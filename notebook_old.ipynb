{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text length: 1115393\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "with open(\"data/input.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(f\"Text length: {len(text)}\")\n",
    "\n",
    "first_60 = text[:60]\n",
    "print(f\"{first_60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| |!|$|&|'|,|-|.|3|:|;|?|A|B|C|D|E|F|G|H|I|J|K|L|M|N|O|P|Q|R|S|T|U|V|W|X|Y|Z|a|b|c|d|e|f|g|h|i|j|k|l|m|n|o|p|q|r|s|t|u|v|w|x|y|z\n",
      "Unique characters: 65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print('|'.join(chars))\n",
    "print(f\"Unique characters: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8]\n"
     ]
    }
   ],
   "source": [
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "print(encode(first_60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47])\n",
      "when input is tensor([18]) the target is 47\n",
      "when input is tensor([18, 47]) the target is 56\n",
      "when input is tensor([18, 47, 56]) the target is 57\n",
      "when input is tensor([18, 47, 56, 57]) the target is 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target is 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target is 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target is 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target is 58\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text))\n",
    "\n",
    "# split into train and validation\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "block_size = 8\n",
    "\n",
    "# 9 items will have 8 predicion examples\n",
    "train_data[:block_size+1]\n",
    "\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "print(x)\n",
    "\n",
    "# useful so the transformer is used to seeing different lengths of data\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target is {target}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: perplexity: 112.3, \n",
      "step 500: perplexity: 27.1, \n",
      "step 1000: perplexity: 15.6, \n",
      "step 1500: perplexity: 13.1, \n",
      "step 2000: perplexity: 12.4, \n",
      "step 2500: perplexity: 12.1, \n",
      "step 3000: perplexity: 11.9, \n",
      "step 3500: perplexity: 11.9, \n",
      "step 4000: perplexity: 11.8, \n",
      "step 4500: perplexity: 11.8, \n",
      "step 5000: perplexity: 11.7, \n"
     ]
    }
   ],
   "source": [
    "from src import SimpleBigramLanguageModel, BatchLoader, Evaluator, Trainer\n",
    "\n",
    "batch_size = 32\n",
    "block_size = 16\n",
    "max_iters = 4500\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-3\n",
    "\n",
    "# Setup data and model\n",
    "torch.manual_seed(1337)\n",
    "train_loader = BatchLoader(train_data, block_size=block_size, batch_size=batch_size)\n",
    "val_loader = BatchLoader(val_data, block_size=block_size, batch_size=batch_size)\n",
    "\n",
    "# model = SimpleBigramLanguageModel(vocab_size, n_embed, block_size)\n",
    "model = SimpleBigramLanguageModel(vocab_size, block_size)\n",
    "\n",
    "# Setup training components\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "evaluator = Evaluator(model, train_loader, val_loader, vocab_size)\n",
    "trainer = Trainer(model, optimizer, train_loader, evaluator, max_iters, eval_interval)\n",
    "\n",
    "# Train the model\n",
    "final_losses = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "O:\n",
      "Anele er fe co,\n",
      "LLamer squsethaittthtr ayit tifod rer; y e ined guratosoulyequg.\n",
      "BUEEd tavaperelee athavis u warray, n\n",
      "We by bronond man, d cr miowivero agarlan\n",
      "has,\n",
      "\n",
      "Binksue; ain'lilavealeamy y t Isoup uge o'sth r.\n",
      "What Beeethisunded orachigorsh kn, Ta cheneinhit we t,\n",
      "Fr s ide Bus ithikee me;\n",
      "Bul ake har apy ave I arillevVIO hineeo n:\n",
      "TI ad by andulcavis, scld\n",
      "Atlithe day;\n",
      "\n",
      "AO: T:\n",
      "G butor benkeave y'd,\n",
      "Gecknfime ttinthalond sBy wapiorasonou haverl the heayet asen d bor t man pe, t\n"
     ]
    }
   ],
   "source": [
    "# Generate some text\n",
    "context = torch.zeros((1, 1), dtype=torch.long)\n",
    "generated_text = decode(model.generate(context, max_new_tokens=490)[0].tolist())\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: perplexity: 65.9, \n",
      "step 500: perplexity: 8.7, \n",
      "step 1000: perplexity: 7.6, \n",
      "step 1500: perplexity: 7.1, \n",
      "step 2000: perplexity: 6.8, \n",
      "step 2500: perplexity: 6.6, \n",
      "step 3000: perplexity: 6.4, \n",
      "step 3500: perplexity: 6.4, \n",
      "step 4000: perplexity: 6.2, \n",
      "step 4500: perplexity: 6.2, \n",
      "step 5000: perplexity: 6.1, \n"
     ]
    }
   ],
   "source": [
    "from src import BigramLanguageModel\n",
    "\n",
    "# Model parameters\n",
    "batch_size = 32\n",
    "block_size = 16\n",
    "max_iters = 4001\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-3\n",
    "n_embed = 64\n",
    "n_heads = 4\n",
    "n_layer = 1\n",
    "dropout = 0.1\n",
    "#\n",
    "\n",
    "# model = SimpleBigramLanguageModel(vocab_size, n_embed, block_size)\n",
    "model = BigramLanguageModel(vocab_size, n_embed, block_size, n_layer, n_heads, dropout)\n",
    "\n",
    "# Setup training components\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "evaluator = Evaluator(model, train_loader, val_loader, vocab_size)\n",
    "trainer = Trainer(model, optimizer, train_loader, evaluator, max_iters, eval_interval)\n",
    "\n",
    "# Train the model\n",
    "final_losses = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "your bes, you as: nowful hear of nold; ward. bath hed lequieds a firt nobor, we have's can to fordids me forim stul of them grabless wind mons to rewind, gays, buthit gner upon\n",
      "to til Roe sive ve thoughd pods.\n",
      "That thols, and tame, you seas, fightr, dors soo stae woung, tet, is of com staiser.\n",
      "\n",
      "Sher.'t Caren: out be het righs. your peaut wapes, in sie;\n",
      "This to my, this, twer one and med fea kin, we balwans fight rove Rorand don-hil man\n",
      "I word, seer no, awrad youghtrise:\n",
      "Stto hy pove, and hond an\n"
     ]
    }
   ],
   "source": [
    "# Generate some text\n",
    "context = torch.zeros((1, 1), dtype=torch.long)\n",
    "generated_text = decode(model.generate(context, max_new_tokens=300)[0].tolist())\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: perplexity: 4412.1, \n",
      "step 500: perplexity: 7.6, \n",
      "step 1000: perplexity: 6.7, \n",
      "step 1500: perplexity: 6.2, \n",
      "step 2000: perplexity: 6.0, \n",
      "step 2500: perplexity: 5.8, \n",
      "step 3000: perplexity: 5.7, \n",
      "step 3500: perplexity: 5.5, \n",
      "step 4000: perplexity: 5.5, \n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "batch_size = 32\n",
    "block_size = 6\n",
    "max_iters = 4001\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-3\n",
    "n_embed = 192\n",
    "n_heads = 3\n",
    "n_layer = 4\n",
    "dropout = 0.1\n",
    "#\n",
    "\n",
    "# model = SimpleBigramLanguageModel(vocab_size, n_embed, block_size)\n",
    "model = BigramLanguageModel(vocab_size, n_embed, block_size, n_layer, n_heads, dropout)\n",
    "\n",
    "# Setup training components\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "evaluator = Evaluator(model, train_loader, val_loader, vocab_size)\n",
    "trainer = Trainer(model, optimizer, train_loader, evaluator, max_iters, eval_interval)\n",
    "\n",
    "# Train the model\n",
    "final_losses = trainer.train()\n",
    "\n",
    "# 2.09 5.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NOR YORK:\n",
      "Love fring.\n",
      "\n",
      "LADY CAPULET:\n",
      "King Esell own so it not by\n",
      "here to I will love thee.\n",
      "\n",
      "SICINIUS:\n",
      "Action; porder.\n",
      "Who on the me proction.\n",
      "Now you the words my mercest fornight\n",
      "That a reconk lay to before-jasts a contern:\n",
      "O grath?\n",
      "\n",
      "COMINIUS:\n",
      "No fro to'th with your gruerm of mror now\n",
      "on yous: to't!' then't Cabsughtly senator\n",
      "Your chage\n",
      "Fausenue to the such in shive.\n",
      "Will bord, my exaincin, and M\n"
     ]
    }
   ],
   "source": [
    "# Generate some text\n",
    "context = torch.zeros((1, 1), dtype=torch.long)\n",
    "generated_text = decode(model.generate(context, max_new_tokens=400)[0].tolist())\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
